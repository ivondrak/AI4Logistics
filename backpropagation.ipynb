{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from Monte-Carlo Simulation\n",
    "### Training neural net\n",
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from backpropagation import BackPropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set from the simulation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0.021,\n",
       "   0.09,\n",
       "   0.259,\n",
       "   0.342,\n",
       "   0.211,\n",
       "   0.062,\n",
       "   0.011,\n",
       "   0.002,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.051,\n",
       "   0.212,\n",
       "   0.461,\n",
       "   0.234,\n",
       "   0.034,\n",
       "   0.007,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.489, 0.491, 0.018, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.027,\n",
       "   0.102,\n",
       "   0.258,\n",
       "   0.355,\n",
       "   0.182,\n",
       "   0.062,\n",
       "   0.009,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.048,\n",
       "   0.233,\n",
       "   0.468,\n",
       "   0.207,\n",
       "   0.037,\n",
       "   0.006,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.473, 0.504, 0.023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.024,\n",
       "   0.087,\n",
       "   0.246,\n",
       "   0.378,\n",
       "   0.201,\n",
       "   0.05,\n",
       "   0.009,\n",
       "   0.003,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.042,\n",
       "   0.232,\n",
       "   0.465,\n",
       "   0.219,\n",
       "   0.036,\n",
       "   0.006,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.468, 0.513, 0.019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.027,\n",
       "   0.083,\n",
       "   0.267,\n",
       "   0.355,\n",
       "   0.201,\n",
       "   0.047,\n",
       "   0.014,\n",
       "   0.005,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.052,\n",
       "   0.24,\n",
       "   0.475,\n",
       "   0.195,\n",
       "   0.031,\n",
       "   0.005,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.506, 0.477, 0.017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.031,\n",
       "   0.096,\n",
       "   0.29,\n",
       "   0.33,\n",
       "   0.19,\n",
       "   0.044,\n",
       "   0.016,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.049,\n",
       "   0.205,\n",
       "   0.496,\n",
       "   0.201,\n",
       "   0.042,\n",
       "   0.005,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.452, 0.516, 0.029, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.028,\n",
       "   0.093,\n",
       "   0.235,\n",
       "   0.376,\n",
       "   0.192,\n",
       "   0.056,\n",
       "   0.013,\n",
       "   0.006,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.05,\n",
       "   0.222,\n",
       "   0.449,\n",
       "   0.241,\n",
       "   0.033,\n",
       "   0.004,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.454, 0.532, 0.012, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.037,\n",
       "   0.076,\n",
       "   0.251,\n",
       "   0.361,\n",
       "   0.196,\n",
       "   0.057,\n",
       "   0.017,\n",
       "   0.005,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.043,\n",
       "   0.238,\n",
       "   0.441,\n",
       "   0.226,\n",
       "   0.044,\n",
       "   0.008,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.439, 0.527, 0.033, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.023,\n",
       "   0.079,\n",
       "   0.269,\n",
       "   0.377,\n",
       "   0.186,\n",
       "   0.055,\n",
       "   0.009,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.038,\n",
       "   0.244,\n",
       "   0.457,\n",
       "   0.222,\n",
       "   0.035,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.459, 0.532, 0.009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.024,\n",
       "   0.087,\n",
       "   0.257,\n",
       "   0.358,\n",
       "   0.201,\n",
       "   0.051,\n",
       "   0.015,\n",
       "   0.006,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.055,\n",
       "   0.222,\n",
       "   0.457,\n",
       "   0.229,\n",
       "   0.031,\n",
       "   0.005,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.51, 0.47, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.025,\n",
       "   0.091,\n",
       "   0.27,\n",
       "   0.339,\n",
       "   0.212,\n",
       "   0.054,\n",
       "   0.007,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.049,\n",
       "   0.234,\n",
       "   0.469,\n",
       "   0.213,\n",
       "   0.03,\n",
       "   0.003,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.464, 0.52, 0.014, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.181,\n",
       "   0.315,\n",
       "   0.313,\n",
       "   0.152,\n",
       "   0.033,\n",
       "   0.003,\n",
       "   0.003,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.045,\n",
       "   0.23,\n",
       "   0.479,\n",
       "   0.197,\n",
       "   0.043,\n",
       "   0.004,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.229, 0.428, 0.195, 0.097, 0.03, 0.013, 0.005, 0.002, 0.001, 0.0]),\n",
       " ([0.165,\n",
       "   0.322,\n",
       "   0.321,\n",
       "   0.149,\n",
       "   0.032,\n",
       "   0.011,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.055,\n",
       "   0.251,\n",
       "   0.448,\n",
       "   0.199,\n",
       "   0.037,\n",
       "   0.007,\n",
       "   0.002,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.248, 0.427, 0.165, 0.082, 0.057, 0.015, 0.003, 0.003, 0.0, 0.0]),\n",
       " ([0.178,\n",
       "   0.288,\n",
       "   0.323,\n",
       "   0.155,\n",
       "   0.042,\n",
       "   0.013,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.053,\n",
       "   0.231,\n",
       "   0.44,\n",
       "   0.228,\n",
       "   0.039,\n",
       "   0.008,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.253, 0.437, 0.149, 0.097, 0.045, 0.012, 0.006, 0.001, 0.0, 0.0]),\n",
       " ([0.168,\n",
       "   0.345,\n",
       "   0.317,\n",
       "   0.125,\n",
       "   0.036,\n",
       "   0.009,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05,\n",
       "   0.243,\n",
       "   0.468,\n",
       "   0.199,\n",
       "   0.036,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.226, 0.449, 0.203, 0.071, 0.044, 0.007, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.188,\n",
       "   0.302,\n",
       "   0.324,\n",
       "   0.142,\n",
       "   0.034,\n",
       "   0.007,\n",
       "   0.003,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.048,\n",
       "   0.246,\n",
       "   0.421,\n",
       "   0.243,\n",
       "   0.035,\n",
       "   0.005,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.209, 0.449, 0.186, 0.08, 0.042, 0.02, 0.007, 0.002, 0.005, 0.0]),\n",
       " ([0.184,\n",
       "   0.336,\n",
       "   0.302,\n",
       "   0.133,\n",
       "   0.032,\n",
       "   0.011,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.051,\n",
       "   0.214,\n",
       "   0.463,\n",
       "   0.226,\n",
       "   0.042,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.2044088176352706,\n",
       "   0.4238476953907815,\n",
       "   0.1753507014028056,\n",
       "   0.0781563126252505,\n",
       "   0.06713426853707415,\n",
       "   0.02905811623246493,\n",
       "   0.01202404809619238,\n",
       "   0.003006012024048096,\n",
       "   0.002004008016032064,\n",
       "   0.00501002004008016]),\n",
       " ([0.17,\n",
       "   0.325,\n",
       "   0.34,\n",
       "   0.135,\n",
       "   0.02,\n",
       "   0.008,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.046,\n",
       "   0.221,\n",
       "   0.449,\n",
       "   0.23,\n",
       "   0.045,\n",
       "   0.007,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.207, 0.42, 0.19, 0.083, 0.047, 0.029, 0.017, 0.006, 0.001, 0.0]),\n",
       " ([0.183,\n",
       "   0.318,\n",
       "   0.317,\n",
       "   0.125,\n",
       "   0.049,\n",
       "   0.006,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.055,\n",
       "   0.252,\n",
       "   0.418,\n",
       "   0.229,\n",
       "   0.042,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.227, 0.448, 0.2, 0.088, 0.024, 0.012, 0.001, 0.0, 0.0, 0.0]),\n",
       " ([0.201,\n",
       "   0.334,\n",
       "   0.297,\n",
       "   0.121,\n",
       "   0.035,\n",
       "   0.01,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.039,\n",
       "   0.238,\n",
       "   0.474,\n",
       "   0.203,\n",
       "   0.038,\n",
       "   0.008,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.18, 0.371, 0.207, 0.111, 0.081, 0.033, 0.007, 0.002, 0.006, 0.002]),\n",
       " ([0.188,\n",
       "   0.314,\n",
       "   0.279,\n",
       "   0.145,\n",
       "   0.053,\n",
       "   0.015,\n",
       "   0.005,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.041,\n",
       "   0.197,\n",
       "   0.485,\n",
       "   0.219,\n",
       "   0.048,\n",
       "   0.01,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.189, 0.442, 0.207, 0.085, 0.039, 0.016, 0.016, 0.004, 0.002, 0.0]),\n",
       " ([0.273,\n",
       "   0.339,\n",
       "   0.268,\n",
       "   0.099,\n",
       "   0.015,\n",
       "   0.006,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.63,\n",
       "   0.282,\n",
       "   0.076,\n",
       "   0.011,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.928, 0.07, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.278,\n",
       "   0.34,\n",
       "   0.25,\n",
       "   0.091,\n",
       "   0.032,\n",
       "   0.008,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.624,\n",
       "   0.309,\n",
       "   0.051,\n",
       "   0.015,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.933, 0.067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.29,\n",
       "   0.351,\n",
       "   0.239,\n",
       "   0.089,\n",
       "   0.025,\n",
       "   0.005,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.62,\n",
       "   0.304,\n",
       "   0.067,\n",
       "   0.007,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.922, 0.077, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.268,\n",
       "   0.368,\n",
       "   0.242,\n",
       "   0.098,\n",
       "   0.018,\n",
       "   0.003,\n",
       "   0.003,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.602,\n",
       "   0.314,\n",
       "   0.07,\n",
       "   0.013,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.913, 0.085, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.279,\n",
       "   0.335,\n",
       "   0.273,\n",
       "   0.082,\n",
       "   0.026,\n",
       "   0.005,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.599,\n",
       "   0.318,\n",
       "   0.075,\n",
       "   0.007,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.924, 0.075, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.293,\n",
       "   0.332,\n",
       "   0.25,\n",
       "   0.095,\n",
       "   0.022,\n",
       "   0.004,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.65,\n",
       "   0.277,\n",
       "   0.063,\n",
       "   0.006,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.93, 0.069, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.263,\n",
       "   0.376,\n",
       "   0.235,\n",
       "   0.098,\n",
       "   0.02,\n",
       "   0.007,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.631,\n",
       "   0.273,\n",
       "   0.083,\n",
       "   0.012,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.907, 0.093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.251,\n",
       "   0.352,\n",
       "   0.272,\n",
       "   0.093,\n",
       "   0.026,\n",
       "   0.004,\n",
       "   0.002,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.592,\n",
       "   0.319,\n",
       "   0.074,\n",
       "   0.013,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.903, 0.089, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.257,\n",
       "   0.344,\n",
       "   0.274,\n",
       "   0.095,\n",
       "   0.02,\n",
       "   0.006,\n",
       "   0.004,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.649,\n",
       "   0.277,\n",
       "   0.069,\n",
       "   0.004,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.927, 0.07, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.257,\n",
       "   0.357,\n",
       "   0.256,\n",
       "   0.101,\n",
       "   0.025,\n",
       "   0.003,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.613,\n",
       "   0.305,\n",
       "   0.075,\n",
       "   0.005,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.001,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.936, 0.062, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ([0.117,\n",
       "   0.111,\n",
       "   0.099,\n",
       "   0.096,\n",
       "   0.085,\n",
       "   0.082,\n",
       "   0.094,\n",
       "   0.106,\n",
       "   0.098,\n",
       "   0.112,\n",
       "   0.026,\n",
       "   0.108,\n",
       "   0.102,\n",
       "   0.095,\n",
       "   0.117,\n",
       "   0.105,\n",
       "   0.124,\n",
       "   0.111,\n",
       "   0.103,\n",
       "   0.109],\n",
       "  [0.0821501014198783,\n",
       "   0.167342799188641,\n",
       "   0.204868154158215,\n",
       "   0.2068965517241379,\n",
       "   0.1156186612576065,\n",
       "   0.08823529411764706,\n",
       "   0.06085192697768763,\n",
       "   0.03549695740365112,\n",
       "   0.02535496957403651,\n",
       "   0.01318458417849899]),\n",
       " ([0.118,\n",
       "   0.09,\n",
       "   0.09,\n",
       "   0.108,\n",
       "   0.099,\n",
       "   0.102,\n",
       "   0.1,\n",
       "   0.09,\n",
       "   0.107,\n",
       "   0.096,\n",
       "   0.029,\n",
       "   0.096,\n",
       "   0.116,\n",
       "   0.11,\n",
       "   0.105,\n",
       "   0.103,\n",
       "   0.117,\n",
       "   0.112,\n",
       "   0.107,\n",
       "   0.105],\n",
       "  [0.09333333333333334,\n",
       "   0.1825641025641026,\n",
       "   0.2061538461538462,\n",
       "   0.2369230769230769,\n",
       "   0.1005128205128205,\n",
       "   0.06461538461538462,\n",
       "   0.05128205128205128,\n",
       "   0.02974358974358974,\n",
       "   0.01846153846153846,\n",
       "   0.01641025641025641]),\n",
       " ([0.095,\n",
       "   0.095,\n",
       "   0.12,\n",
       "   0.101,\n",
       "   0.092,\n",
       "   0.094,\n",
       "   0.089,\n",
       "   0.113,\n",
       "   0.097,\n",
       "   0.104,\n",
       "   0.031,\n",
       "   0.105,\n",
       "   0.113,\n",
       "   0.112,\n",
       "   0.107,\n",
       "   0.097,\n",
       "   0.099,\n",
       "   0.103,\n",
       "   0.122,\n",
       "   0.111],\n",
       "  [0.08926673751328375,\n",
       "   0.1647183846971307,\n",
       "   0.1944739638682253,\n",
       "   0.255047821466525,\n",
       "   0.08926673751328375,\n",
       "   0.08395324123273114,\n",
       "   0.04038257173219979,\n",
       "   0.04357066950053135,\n",
       "   0.01806588735387885,\n",
       "   0.02125398512221041]),\n",
       " ([0.105,\n",
       "   0.099,\n",
       "   0.098,\n",
       "   0.106,\n",
       "   0.086,\n",
       "   0.09,\n",
       "   0.096,\n",
       "   0.113,\n",
       "   0.108,\n",
       "   0.099,\n",
       "   0.034,\n",
       "   0.109,\n",
       "   0.104,\n",
       "   0.119,\n",
       "   0.088,\n",
       "   0.093,\n",
       "   0.098,\n",
       "   0.106,\n",
       "   0.131,\n",
       "   0.118],\n",
       "  [0.09412955465587045,\n",
       "   0.159919028340081,\n",
       "   0.1882591093117409,\n",
       "   0.2692307692307692,\n",
       "   0.104251012145749,\n",
       "   0.07793522267206478,\n",
       "   0.048582995951417,\n",
       "   0.04251012145748988,\n",
       "   0.008097165991902834,\n",
       "   0.00708502024291498]),\n",
       " ([0.11,\n",
       "   0.109,\n",
       "   0.111,\n",
       "   0.085,\n",
       "   0.11,\n",
       "   0.091,\n",
       "   0.096,\n",
       "   0.093,\n",
       "   0.087,\n",
       "   0.108,\n",
       "   0.027,\n",
       "   0.112,\n",
       "   0.103,\n",
       "   0.125,\n",
       "   0.097,\n",
       "   0.114,\n",
       "   0.115,\n",
       "   0.089,\n",
       "   0.103,\n",
       "   0.115],\n",
       "  [0.09989701338825953,\n",
       "   0.1833161688980433,\n",
       "   0.2152420185375901,\n",
       "   0.2306900102986612,\n",
       "   0.07723995880535531,\n",
       "   0.09268795056642637,\n",
       "   0.0411946446961895,\n",
       "   0.03089598352214212,\n",
       "   0.01441812564366632,\n",
       "   0.01441812564366632]),\n",
       " ([0.127,\n",
       "   0.103,\n",
       "   0.088,\n",
       "   0.103,\n",
       "   0.1,\n",
       "   0.091,\n",
       "   0.088,\n",
       "   0.092,\n",
       "   0.099,\n",
       "   0.109,\n",
       "   0.025,\n",
       "   0.111,\n",
       "   0.098,\n",
       "   0.114,\n",
       "   0.116,\n",
       "   0.108,\n",
       "   0.097,\n",
       "   0.121,\n",
       "   0.099,\n",
       "   0.111],\n",
       "  [0.1027542372881356,\n",
       "   0.1684322033898305,\n",
       "   0.1822033898305085,\n",
       "   0.2171610169491525,\n",
       "   0.1048728813559322,\n",
       "   0.07203389830508475,\n",
       "   0.04872881355932204,\n",
       "   0.04872881355932204,\n",
       "   0.03283898305084746,\n",
       "   0.02224576271186441]),\n",
       " ([0.094,\n",
       "   0.099,\n",
       "   0.087,\n",
       "   0.108,\n",
       "   0.098,\n",
       "   0.112,\n",
       "   0.094,\n",
       "   0.102,\n",
       "   0.115,\n",
       "   0.091,\n",
       "   0.024,\n",
       "   0.099,\n",
       "   0.122,\n",
       "   0.11,\n",
       "   0.101,\n",
       "   0.118,\n",
       "   0.105,\n",
       "   0.102,\n",
       "   0.109,\n",
       "   0.11],\n",
       "  [0.09137577002053388,\n",
       "   0.1817248459958932,\n",
       "   0.2268993839835729,\n",
       "   0.2053388090349076,\n",
       "   0.09650924024640657,\n",
       "   0.08213552361396304,\n",
       "   0.0513347022587269,\n",
       "   0.02874743326488706,\n",
       "   0.0215605749486653,\n",
       "   0.01437371663244353]),\n",
       " ([0.106,\n",
       "   0.096,\n",
       "   0.099,\n",
       "   0.105,\n",
       "   0.099,\n",
       "   0.088,\n",
       "   0.09,\n",
       "   0.092,\n",
       "   0.121,\n",
       "   0.104,\n",
       "   0.025,\n",
       "   0.105,\n",
       "   0.103,\n",
       "   0.104,\n",
       "   0.116,\n",
       "   0.108,\n",
       "   0.112,\n",
       "   0.102,\n",
       "   0.113,\n",
       "   0.112],\n",
       "  [0.1118012422360248,\n",
       "   0.1511387163561076,\n",
       "   0.1966873706004141,\n",
       "   0.2422360248447205,\n",
       "   0.08178053830227744,\n",
       "   0.07971014492753623,\n",
       "   0.05486542443064182,\n",
       "   0.03312629399585922,\n",
       "   0.02898550724637681,\n",
       "   0.01966873706004141]),\n",
       " ([0.11,\n",
       "   0.117,\n",
       "   0.082,\n",
       "   0.11,\n",
       "   0.085,\n",
       "   0.098,\n",
       "   0.075,\n",
       "   0.103,\n",
       "   0.107,\n",
       "   0.113,\n",
       "   0.024,\n",
       "   0.104,\n",
       "   0.11,\n",
       "   0.099,\n",
       "   0.111,\n",
       "   0.116,\n",
       "   0.106,\n",
       "   0.113,\n",
       "   0.104,\n",
       "   0.113],\n",
       "  [0.08921161825726141,\n",
       "   0.1867219917012448,\n",
       "   0.204356846473029,\n",
       "   0.2147302904564315,\n",
       "   0.09439834024896265,\n",
       "   0.07468879668049792,\n",
       "   0.06016597510373444,\n",
       "   0.04356846473029045,\n",
       "   0.01556016597510373,\n",
       "   0.01659751037344398]),\n",
       " ([0.095,\n",
       "   0.092,\n",
       "   0.097,\n",
       "   0.08,\n",
       "   0.087,\n",
       "   0.109,\n",
       "   0.111,\n",
       "   0.106,\n",
       "   0.123,\n",
       "   0.1,\n",
       "   0.034,\n",
       "   0.103,\n",
       "   0.107,\n",
       "   0.113,\n",
       "   0.094,\n",
       "   0.106,\n",
       "   0.117,\n",
       "   0.124,\n",
       "   0.092,\n",
       "   0.11],\n",
       "  [0.1158536585365854,\n",
       "   0.1839430894308943,\n",
       "   0.2103658536585366,\n",
       "   0.2215447154471545,\n",
       "   0.09857723577235772,\n",
       "   0.08231707317073171,\n",
       "   0.04674796747967479,\n",
       "   0.02540650406504065,\n",
       "   0.006097560975609756,\n",
       "   0.009146341463414634])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('training_set.xlsx')\n",
    "\n",
    "#data.head()\n",
    "training_set = []\n",
    "for index, row in data.iterrows():\n",
    "    features = row.iloc[:20].tolist()  \n",
    "    result = row.iloc[-10:].tolist() \n",
    "    training_set.append((features, result))\n",
    "    \n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn multilayered neural network with a given training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [0.021, 0.09, 0.259, 0.342, 0.211, 0.062, 0.011, 0.002, 0.002, 0.0, 0.051, 0.212, 0.461, 0.234, 0.034, 0.007, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.027, 0.102, 0.258, 0.355, 0.182, 0.062, 0.009, 0.004, 0.0, 0.001, 0.048, 0.233, 0.468, 0.207, 0.037, 0.006, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.024, 0.087, 0.246, 0.378, 0.201, 0.05, 0.009, 0.003, 0.002, 0.0, 0.042, 0.232, 0.465, 0.219, 0.036, 0.006, 0.0, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.027, 0.083, 0.267, 0.355, 0.201, 0.047, 0.014, 0.005, 0.001, 0.0, 0.052, 0.24, 0.475, 0.195, 0.031, 0.005, 0.002, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.031, 0.096, 0.29, 0.33, 0.19, 0.044, 0.016, 0.002, 0.0, 0.001, 0.049, 0.205, 0.496, 0.201, 0.042, 0.005, 0.002, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.028, 0.093, 0.235, 0.376, 0.192, 0.056, 0.013, 0.006, 0.001, 0.0, 0.05, 0.222, 0.449, 0.241, 0.033, 0.004, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.037, 0.076, 0.251, 0.361, 0.196, 0.057, 0.017, 0.005, 0.0, 0.0, 0.043, 0.238, 0.441, 0.226, 0.044, 0.008, 0.0, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.023, 0.079, 0.269, 0.377, 0.186, 0.055, 0.009, 0.002, 0.0, 0.0, 0.038, 0.244, 0.457, 0.222, 0.035, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.024, 0.087, 0.257, 0.358, 0.201, 0.051, 0.015, 0.006, 0.001, 0.0, 0.055, 0.222, 0.457, 0.229, 0.031, 0.005, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.025, 0.091, 0.27, 0.339, 0.212, 0.054, 0.007, 0.001, 0.001, 0.0, 0.049, 0.234, 0.469, 0.213, 0.03, 0.003, 0.002, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.181, 0.315, 0.313, 0.152, 0.033, 0.003, 0.003, 0.0, 0.0, 0.0, 0.045, 0.23, 0.479, 0.197, 0.043, 0.004, 0.001, 0.001, 0.0, 0.0]  Output:  [0.21, 0.45, 0.19, 0.08, 0.04, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.165, 0.322, 0.321, 0.149, 0.032, 0.011, 0.0, 0.0, 0.0, 0.0, 0.055, 0.251, 0.448, 0.199, 0.037, 0.007, 0.002, 0.001, 0.0, 0.0]  Output:  [0.25, 0.44, 0.17, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.178, 0.288, 0.323, 0.155, 0.042, 0.013, 0.001, 0.0, 0.0, 0.0, 0.053, 0.231, 0.44, 0.228, 0.039, 0.008, 0.001, 0.0, 0.0, 0.0]  Output:  [0.25, 0.45, 0.17, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.168, 0.345, 0.317, 0.125, 0.036, 0.009, 0.0, 0.0, 0.0, 0.0, 0.05, 0.243, 0.468, 0.199, 0.036, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.21, 0.45, 0.19, 0.08, 0.04, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.188, 0.302, 0.324, 0.142, 0.034, 0.007, 0.003, 0.0, 0.0, 0.0, 0.048, 0.246, 0.421, 0.243, 0.035, 0.005, 0.001, 0.001, 0.0, 0.0]  Output:  [0.21, 0.45, 0.19, 0.08, 0.04, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.184, 0.336, 0.302, 0.133, 0.032, 0.011, 0.001, 0.001, 0.0, 0.0, 0.051, 0.214, 0.463, 0.226, 0.042, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.19, 0.43, 0.2, 0.09, 0.05, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.17, 0.325, 0.34, 0.135, 0.02, 0.008, 0.001, 0.0, 0.001, 0.0, 0.046, 0.221, 0.449, 0.23, 0.045, 0.007, 0.002, 0.0, 0.0, 0.0]  Output:  [0.19, 0.44, 0.2, 0.09, 0.05, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.183, 0.318, 0.317, 0.125, 0.049, 0.006, 0.001, 0.0, 0.001, 0.0, 0.055, 0.252, 0.418, 0.229, 0.042, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.21, 0.45, 0.19, 0.08, 0.04, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.201, 0.334, 0.297, 0.121, 0.035, 0.01, 0.001, 0.0, 0.001, 0.0, 0.039, 0.238, 0.474, 0.203, 0.038, 0.008, 0.0, 0.0, 0.0, 0.0]  Output:  [0.18, 0.36, 0.21, 0.1, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.188, 0.314, 0.279, 0.145, 0.053, 0.015, 0.005, 0.001, 0.0, 0.0, 0.041, 0.197, 0.485, 0.219, 0.048, 0.01, 0.0, 0.0, 0.0, 0.0]  Output:  [0.19, 0.45, 0.2, 0.09, 0.05, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.273, 0.339, 0.268, 0.099, 0.015, 0.006, 0.0, 0.0, 0.0, 0.0, 0.63, 0.282, 0.076, 0.011, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.278, 0.34, 0.25, 0.091, 0.032, 0.008, 0.001, 0.0, 0.0, 0.0, 0.624, 0.309, 0.051, 0.015, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.29, 0.351, 0.239, 0.089, 0.025, 0.005, 0.001, 0.0, 0.0, 0.0, 0.62, 0.304, 0.067, 0.007, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.268, 0.368, 0.242, 0.098, 0.018, 0.003, 0.003, 0.0, 0.0, 0.0, 0.602, 0.314, 0.07, 0.013, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.279, 0.335, 0.273, 0.082, 0.026, 0.005, 0.0, 0.0, 0.0, 0.0, 0.599, 0.318, 0.075, 0.007, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.293, 0.332, 0.25, 0.095, 0.022, 0.004, 0.004, 0.0, 0.0, 0.0, 0.65, 0.277, 0.063, 0.006, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.263, 0.376, 0.235, 0.098, 0.02, 0.007, 0.0, 0.001, 0.0, 0.0, 0.631, 0.273, 0.083, 0.012, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.251, 0.352, 0.272, 0.093, 0.026, 0.004, 0.002, 0.0, 0.0, 0.0, 0.592, 0.319, 0.074, 0.013, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.257, 0.344, 0.274, 0.095, 0.02, 0.006, 0.004, 0.0, 0.0, 0.0, 0.649, 0.277, 0.069, 0.004, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.257, 0.357, 0.256, 0.101, 0.025, 0.003, 0.001, 0.0, 0.0, 0.0, 0.613, 0.305, 0.075, 0.005, 0.001, 0.0, 0.001, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.117, 0.111, 0.099, 0.096, 0.085, 0.082, 0.094, 0.106, 0.098, 0.112, 0.026, 0.108, 0.102, 0.095, 0.117, 0.105, 0.124, 0.111, 0.103, 0.109]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.118, 0.09, 0.09, 0.108, 0.099, 0.102, 0.1, 0.09, 0.107, 0.096, 0.029, 0.096, 0.116, 0.11, 0.105, 0.103, 0.117, 0.112, 0.107, 0.105]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.095, 0.095, 0.12, 0.101, 0.092, 0.094, 0.089, 0.113, 0.097, 0.104, 0.031, 0.105, 0.113, 0.112, 0.107, 0.097, 0.099, 0.103, 0.122, 0.111]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.105, 0.099, 0.098, 0.106, 0.086, 0.09, 0.096, 0.113, 0.108, 0.099, 0.034, 0.109, 0.104, 0.119, 0.088, 0.093, 0.098, 0.106, 0.131, 0.118]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.11, 0.109, 0.111, 0.085, 0.11, 0.091, 0.096, 0.093, 0.087, 0.108, 0.027, 0.112, 0.103, 0.125, 0.097, 0.114, 0.115, 0.089, 0.103, 0.115]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.127, 0.103, 0.088, 0.103, 0.1, 0.091, 0.088, 0.092, 0.099, 0.109, 0.025, 0.111, 0.098, 0.114, 0.116, 0.108, 0.097, 0.121, 0.099, 0.111]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.094, 0.099, 0.087, 0.108, 0.098, 0.112, 0.094, 0.102, 0.115, 0.091, 0.024, 0.099, 0.122, 0.11, 0.101, 0.118, 0.105, 0.102, 0.109, 0.11]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.106, 0.096, 0.099, 0.105, 0.099, 0.088, 0.09, 0.092, 0.121, 0.104, 0.025, 0.105, 0.103, 0.104, 0.116, 0.108, 0.112, 0.102, 0.113, 0.112]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.11, 0.117, 0.082, 0.11, 0.085, 0.098, 0.075, 0.103, 0.107, 0.113, 0.024, 0.104, 0.11, 0.099, 0.111, 0.116, 0.106, 0.113, 0.104, 0.113]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n",
      "Input:  [0.095, 0.092, 0.097, 0.08, 0.087, 0.109, 0.111, 0.106, 0.123, 0.1, 0.034, 0.103, 0.107, 0.113, 0.094, 0.106, 0.117, 0.124, 0.092, 0.11]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n"
     ]
    }
   ],
   "source": [
    "bpnn = BackPropagation(training_set,[20, 15, 15, 10], [0.3, 0.3, 0.3], 10000)\n",
    "bpnn.backpropagation()\n",
    "for row in training_set:\n",
    "    net_input = row[0]\n",
    "    bpnn.feed_forward(net_input)\n",
    "    net_output = bpnn.output_activation.reshape([1,10])\n",
    "    print(\"Input: \", net_input, \" Output: \", net_output.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the history of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bpnn.history)\n",
    "plt.xlabel('Iterace')\n",
    "plt.ylabel('Střední kvadratická chyba')\n",
    "plt.title('Průběh učení')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means squared error:  0.0008221872179545759\n"
     ]
    }
   ],
   "source": [
    "error = bpnn.calculate_mean_squared_error()\n",
    "print(\"Means squared error: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max error of the single output neuron for a training net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error of the single output neuron:  0.040000000000000036\n"
     ]
    }
   ],
   "source": [
    "max_error = bpnn.calculate_max_error()\n",
    "print(\"Max error of the single output neuron: \", max_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find solution for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [0.021, 0.09, 0.259, 0.342, 0.211, 0.062, 0.011, 0.002, 0.002, 0.0, 0.051, 0.212, 0.461, 0.234, 0.034, 0.007, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.181, 0.315, 0.313, 0.152, 0.033, 0.003, 0.003, 0.0, 0.0, 0.0, 0.045, 0.23, 0.479, 0.197, 0.043, 0.004, 0.001, 0.001, 0.0, 0.0]  Output:  [0.21, 0.45, 0.19, 0.08, 0.04, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.273, 0.339, 0.268, 0.099, 0.015, 0.006, 0.0, 0.0, 0.0, 0.0, 0.63, 0.282, 0.076, 0.011, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.117, 0.111, 0.099, 0.096, 0.085, 0.082, 0.094, 0.106, 0.098, 0.112, 0.026, 0.108, 0.102, 0.095, 0.117, 0.105, 0.124, 0.111, 0.103, 0.109]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-0.3</th>\n",
       "      <th>0.3-0.6</th>\n",
       "      <th>0.6-0.9</th>\n",
       "      <th>0.9-1.2</th>\n",
       "      <th>1.2-1.5</th>\n",
       "      <th>1.5-1.8</th>\n",
       "      <th>1.8-2.1</th>\n",
       "      <th>2.1-2.4</th>\n",
       "      <th>2.4-2.7</th>\n",
       "      <th>2.7-3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>0-0.5</th>\n",
       "      <th>0.5-1</th>\n",
       "      <th>1-1.5</th>\n",
       "      <th>1.5-2</th>\n",
       "      <th>2-2.5</th>\n",
       "      <th>2.5-3</th>\n",
       "      <th>3-3.5</th>\n",
       "      <th>3.5-4</th>\n",
       "      <th>4-4.5</th>\n",
       "      <th>4.5-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0-0.3  0.3-0.6  0.6-0.9  0.9-1.2  1.2-1.5  1.5-1.8  1.8-2.1  2.1-2.4  \\\n",
       "0  0.021    0.090    0.259    0.342    0.211    0.062    0.011    0.002   \n",
       "1  0.181    0.315    0.313    0.152    0.033    0.003    0.003    0.000   \n",
       "2  0.273    0.339    0.268    0.099    0.015    0.006    0.000    0.000   \n",
       "3  0.117    0.111    0.099    0.096    0.085    0.082    0.094    0.106   \n",
       "\n",
       "   2.4-2.7  2.7-3.0  ...  0-0.5  0.5-1  1-1.5  1.5-2  2-2.5  2.5-3  3-3.5  \\\n",
       "0    0.002    0.000  ...   0.47   0.51   0.02   0.00   0.00   0.00   0.00   \n",
       "1    0.000    0.000  ...   0.21   0.45   0.19   0.08   0.04   0.02   0.01   \n",
       "2    0.000    0.000  ...   0.92   0.08   0.01   0.00   0.00   0.00   0.00   \n",
       "3    0.098    0.112  ...   0.10   0.17   0.20   0.23   0.10   0.08   0.05   \n",
       "\n",
       "   3.5-4  4-4.5  4.5-5  \n",
       "0   0.00   0.00   0.00  \n",
       "1   0.00   0.00   0.00  \n",
       "2   0.00   0.00   0.00  \n",
       "3   0.04   0.02   0.02  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_excel('inference_set.xlsx')\n",
    "input_data.head()\n",
    "input_set = []\n",
    "for index, row in input_data.iterrows():\n",
    "    features = row.iloc[:20].tolist()\n",
    "    input_set.append(features)\n",
    "\n",
    "output_set = []\n",
    "for net_input in input_set:\n",
    "    net_output = bpnn.run(net_input)\n",
    "    output_set.append(net_output)\n",
    "    print(\"Input: \", net_input, \" Output: \", net_output)\n",
    "# Create a DataFrame for the output data\n",
    "\n",
    "header = list(data.columns)\n",
    "output_data = pd.DataFrame(columns=header)\n",
    "\n",
    "for i in range(len(input_set)):\n",
    "    row = input_set[i] + output_set[i]\n",
    "    output_data.loc[i] = row\n",
    "\n",
    "output_data.to_excel('result_set.xlsx', index=False)\n",
    "output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing generalization capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [0.117, 0.111, 0.099, 0.096, 0.085, 0.082, 0.094, 0.106, 0.098, 0.112, 0.026, 0.108, 0.102, 0.095, 0.117, 0.105, 0.124, 0.111, 0.103, 0.109]  Output:  [0.1, 0.17, 0.2, 0.23, 0.1, 0.08, 0.05, 0.04, 0.02, 0.02]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-0.3</th>\n",
       "      <th>0.3-0.6</th>\n",
       "      <th>0.6-0.9</th>\n",
       "      <th>0.9-1.2</th>\n",
       "      <th>1.2-1.5</th>\n",
       "      <th>1.5-1.8</th>\n",
       "      <th>1.8-2.1</th>\n",
       "      <th>2.1-2.4</th>\n",
       "      <th>2.4-2.7</th>\n",
       "      <th>2.7-3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>0-0.5</th>\n",
       "      <th>0.5-1</th>\n",
       "      <th>1-1.5</th>\n",
       "      <th>1.5-2</th>\n",
       "      <th>2-2.5</th>\n",
       "      <th>2.5-3</th>\n",
       "      <th>3-3.5</th>\n",
       "      <th>3.5-4</th>\n",
       "      <th>4-4.5</th>\n",
       "      <th>4.5-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0-0.3  0.3-0.6  0.6-0.9  0.9-1.2  1.2-1.5  1.5-1.8  1.8-2.1  2.1-2.4  \\\n",
       "0  0.117    0.111    0.099    0.096    0.085    0.082    0.094    0.106   \n",
       "\n",
       "   2.4-2.7  2.7-3.0  ...  0-0.5  0.5-1  1-1.5  1.5-2  2-2.5  2.5-3  3-3.5  \\\n",
       "0    0.098    0.112  ...    0.1   0.17    0.2   0.23    0.1   0.08   0.05   \n",
       "\n",
       "   3.5-4  4-4.5  4.5-5  \n",
       "0   0.04   0.02   0.02  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_excel('uniform_inference_set.xlsx')\n",
    "input_data.head()\n",
    "input_set = []\n",
    "for index, row in input_data.iterrows():\n",
    "    features = row.iloc[:20].tolist()\n",
    "    input_set.append(features)\n",
    "\n",
    "output_set = []\n",
    "for net_input in input_set:\n",
    "    net_output = bpnn.run(net_input)\n",
    "    output_set.append(net_output)\n",
    "    print(\"Input: \", net_input, \" Output: \", net_output)\n",
    "# Create a DataFrame for the output data\n",
    "\n",
    "header = list(data.columns)\n",
    "output_data = pd.DataFrame(columns=header)\n",
    "\n",
    "for i in range(len(input_set)):\n",
    "    row = input_set[i] + output_set[i]\n",
    "    output_data.loc[i] = row\n",
    "\n",
    "output_data.to_excel('uniform_result_set.xlsx', index=False)\n",
    "output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension of the learning set with uniform distribution\n",
    "Ten rows from the table uniform_training_set.xlsx is going to be added to the original training_set.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [0.021, 0.09, 0.259, 0.342, 0.211, 0.062, 0.011, 0.002, 0.002, 0.0, 0.051, 0.212, 0.461, 0.234, 0.034, 0.007, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.027, 0.102, 0.258, 0.355, 0.182, 0.062, 0.009, 0.004, 0.0, 0.001, 0.048, 0.233, 0.468, 0.207, 0.037, 0.006, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.024, 0.087, 0.246, 0.378, 0.201, 0.05, 0.009, 0.003, 0.002, 0.0, 0.042, 0.232, 0.465, 0.219, 0.036, 0.006, 0.0, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.027, 0.083, 0.267, 0.355, 0.201, 0.047, 0.014, 0.005, 0.001, 0.0, 0.052, 0.24, 0.475, 0.195, 0.031, 0.005, 0.002, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.031, 0.096, 0.29, 0.33, 0.19, 0.044, 0.016, 0.002, 0.0, 0.001, 0.049, 0.205, 0.496, 0.201, 0.042, 0.005, 0.002, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.028, 0.093, 0.235, 0.376, 0.192, 0.056, 0.013, 0.006, 0.001, 0.0, 0.05, 0.222, 0.449, 0.241, 0.033, 0.004, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.037, 0.076, 0.251, 0.361, 0.196, 0.057, 0.017, 0.005, 0.0, 0.0, 0.043, 0.238, 0.441, 0.226, 0.044, 0.008, 0.0, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.023, 0.079, 0.269, 0.377, 0.186, 0.055, 0.009, 0.002, 0.0, 0.0, 0.038, 0.244, 0.457, 0.222, 0.035, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.024, 0.087, 0.257, 0.358, 0.201, 0.051, 0.015, 0.006, 0.001, 0.0, 0.055, 0.222, 0.457, 0.229, 0.031, 0.005, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.025, 0.091, 0.27, 0.339, 0.212, 0.054, 0.007, 0.001, 0.001, 0.0, 0.049, 0.234, 0.469, 0.213, 0.03, 0.003, 0.002, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.181, 0.315, 0.313, 0.152, 0.033, 0.003, 0.003, 0.0, 0.0, 0.0, 0.045, 0.23, 0.479, 0.197, 0.043, 0.004, 0.001, 0.001, 0.0, 0.0]  Output:  [0.23, 0.45, 0.19, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.165, 0.322, 0.321, 0.149, 0.032, 0.011, 0.0, 0.0, 0.0, 0.0, 0.055, 0.251, 0.448, 0.199, 0.037, 0.007, 0.002, 0.001, 0.0, 0.0]  Output:  [0.26, 0.45, 0.13, 0.05, 0.02, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.178, 0.288, 0.323, 0.155, 0.042, 0.013, 0.001, 0.0, 0.0, 0.0, 0.053, 0.231, 0.44, 0.228, 0.039, 0.008, 0.001, 0.0, 0.0, 0.0]  Output:  [0.23, 0.44, 0.18, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.168, 0.345, 0.317, 0.125, 0.036, 0.009, 0.0, 0.0, 0.0, 0.0, 0.05, 0.243, 0.468, 0.199, 0.036, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.23, 0.44, 0.18, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.188, 0.302, 0.324, 0.142, 0.034, 0.007, 0.003, 0.0, 0.0, 0.0, 0.048, 0.246, 0.421, 0.243, 0.035, 0.005, 0.001, 0.001, 0.0, 0.0]  Output:  [0.23, 0.44, 0.18, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.184, 0.336, 0.302, 0.133, 0.032, 0.011, 0.001, 0.001, 0.0, 0.0, 0.051, 0.214, 0.463, 0.226, 0.042, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.22, 0.46, 0.19, 0.08, 0.05, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.17, 0.325, 0.34, 0.135, 0.02, 0.008, 0.001, 0.0, 0.001, 0.0, 0.046, 0.221, 0.449, 0.23, 0.045, 0.007, 0.002, 0.0, 0.0, 0.0]  Output:  [0.21, 0.45, 0.19, 0.08, 0.05, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.183, 0.318, 0.317, 0.125, 0.049, 0.006, 0.001, 0.0, 0.001, 0.0, 0.055, 0.252, 0.418, 0.229, 0.042, 0.004, 0.0, 0.0, 0.0, 0.0]  Output:  [0.23, 0.44, 0.18, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.201, 0.334, 0.297, 0.121, 0.035, 0.01, 0.001, 0.0, 0.001, 0.0, 0.039, 0.238, 0.474, 0.203, 0.038, 0.008, 0.0, 0.0, 0.0, 0.0]  Output:  [0.18, 0.38, 0.2, 0.1, 0.06, 0.03, 0.01, 0.01, 0.0, 0.0]\n",
      "Input:  [0.188, 0.314, 0.279, 0.145, 0.053, 0.015, 0.005, 0.001, 0.0, 0.0, 0.041, 0.197, 0.485, 0.219, 0.048, 0.01, 0.0, 0.0, 0.0, 0.0]  Output:  [0.2, 0.44, 0.19, 0.08, 0.06, 0.02, 0.01, 0.0, 0.0, 0.0]\n",
      "Input:  [0.273, 0.339, 0.268, 0.099, 0.015, 0.006, 0.0, 0.0, 0.0, 0.0, 0.63, 0.282, 0.076, 0.011, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.93, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.278, 0.34, 0.25, 0.091, 0.032, 0.008, 0.001, 0.0, 0.0, 0.0, 0.624, 0.309, 0.051, 0.015, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.93, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.29, 0.351, 0.239, 0.089, 0.025, 0.005, 0.001, 0.0, 0.0, 0.0, 0.62, 0.304, 0.067, 0.007, 0.002, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.93, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.268, 0.368, 0.242, 0.098, 0.018, 0.003, 0.003, 0.0, 0.0, 0.0, 0.602, 0.314, 0.07, 0.013, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.279, 0.335, 0.273, 0.082, 0.026, 0.005, 0.0, 0.0, 0.0, 0.0, 0.599, 0.318, 0.075, 0.007, 0.0, 0.001, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.293, 0.332, 0.25, 0.095, 0.022, 0.004, 0.004, 0.0, 0.0, 0.0, 0.65, 0.277, 0.063, 0.006, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.93, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.263, 0.376, 0.235, 0.098, 0.02, 0.007, 0.0, 0.001, 0.0, 0.0, 0.631, 0.273, 0.083, 0.012, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.251, 0.352, 0.272, 0.093, 0.026, 0.004, 0.002, 0.0, 0.0, 0.0, 0.592, 0.319, 0.074, 0.013, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0]  Output:  [0.91, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.257, 0.344, 0.274, 0.095, 0.02, 0.006, 0.004, 0.0, 0.0, 0.0, 0.649, 0.277, 0.069, 0.004, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.93, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.257, 0.357, 0.256, 0.101, 0.025, 0.003, 0.001, 0.0, 0.0, 0.0, 0.613, 0.305, 0.075, 0.005, 0.001, 0.0, 0.001, 0.0, 0.0, 0.0]  Output:  [0.92, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.117, 0.111, 0.099, 0.096, 0.085, 0.082, 0.094, 0.106, 0.098, 0.112, 0.026, 0.108, 0.102, 0.095, 0.117, 0.105, 0.124, 0.111, 0.103, 0.109]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.08, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.118, 0.09, 0.09, 0.108, 0.099, 0.102, 0.1, 0.09, 0.107, 0.096, 0.029, 0.096, 0.116, 0.11, 0.105, 0.103, 0.117, 0.112, 0.107, 0.105]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.07, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.095, 0.095, 0.12, 0.101, 0.092, 0.094, 0.089, 0.113, 0.097, 0.104, 0.031, 0.105, 0.113, 0.112, 0.107, 0.097, 0.099, 0.103, 0.122, 0.111]  Output:  [0.11, 0.19, 0.2, 0.2, 0.09, 0.07, 0.04, 0.03, 0.02, 0.01]\n",
      "Input:  [0.105, 0.099, 0.098, 0.106, 0.086, 0.09, 0.096, 0.113, 0.108, 0.099, 0.034, 0.109, 0.104, 0.119, 0.088, 0.093, 0.098, 0.106, 0.131, 0.118]  Output:  [0.11, 0.19, 0.2, 0.2, 0.09, 0.07, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.11, 0.109, 0.111, 0.085, 0.11, 0.091, 0.096, 0.093, 0.087, 0.108, 0.027, 0.112, 0.103, 0.125, 0.097, 0.114, 0.115, 0.089, 0.103, 0.115]  Output:  [0.11, 0.19, 0.2, 0.2, 0.09, 0.07, 0.04, 0.03, 0.02, 0.01]\n",
      "Input:  [0.127, 0.103, 0.088, 0.103, 0.1, 0.091, 0.088, 0.092, 0.099, 0.109, 0.025, 0.111, 0.098, 0.114, 0.116, 0.108, 0.097, 0.121, 0.099, 0.111]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.08, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.094, 0.099, 0.087, 0.108, 0.098, 0.112, 0.094, 0.102, 0.115, 0.091, 0.024, 0.099, 0.122, 0.11, 0.101, 0.118, 0.105, 0.102, 0.109, 0.11]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.07, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.106, 0.096, 0.099, 0.105, 0.099, 0.088, 0.09, 0.092, 0.121, 0.104, 0.025, 0.105, 0.103, 0.104, 0.116, 0.108, 0.112, 0.102, 0.113, 0.112]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.07, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.11, 0.117, 0.082, 0.11, 0.085, 0.098, 0.075, 0.103, 0.107, 0.113, 0.024, 0.104, 0.11, 0.099, 0.111, 0.116, 0.106, 0.113, 0.104, 0.113]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.08, 0.05, 0.03, 0.02, 0.01]\n",
      "Input:  [0.095, 0.092, 0.097, 0.08, 0.087, 0.109, 0.111, 0.106, 0.123, 0.1, 0.034, 0.103, 0.107, 0.113, 0.094, 0.106, 0.117, 0.124, 0.092, 0.11]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.07, 0.05, 0.03, 0.02, 0.01]\n",
      "Means squared error:  0.0012251342799646137\n",
      "Max error of the single output neuron:  0.0692307692307692\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('training_set.xlsx')\n",
    "\n",
    "#data.head()\n",
    "training_set = []\n",
    "for index, row in data.iterrows():\n",
    "    features = row.iloc[:20].tolist()  \n",
    "    result = row.iloc[-10:].tolist() \n",
    "    training_set.append((features, result))\n",
    "    \n",
    "bpnn = BackPropagation(training_set,[20, 15, 15, 10], [0.3, 0.3, 0.3], 10000)\n",
    "bpnn.backpropagation()\n",
    "for row in training_set:\n",
    "    net_input = row[0]\n",
    "    bpnn.feed_forward(net_input)\n",
    "    net_output = bpnn.output_activation.reshape([1,10])\n",
    "    print(\"Input: \", net_input, \" Output: \", net_output.flatten().tolist())\n",
    "\n",
    "error = bpnn.calculate_mean_squared_error()\n",
    "print(\"Means squared error: \", error)\n",
    "\n",
    "max_error = bpnn.calculate_max_error()\n",
    "print(\"Max error of the single output neuron: \", max_error)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find solution for examples extended with a row for uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [0.021, 0.09, 0.259, 0.342, 0.211, 0.062, 0.011, 0.002, 0.002, 0.0, 0.051, 0.212, 0.461, 0.234, 0.034, 0.007, 0.001, 0.0, 0.0, 0.0]  Output:  [0.47, 0.51, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.181, 0.315, 0.313, 0.152, 0.033, 0.003, 0.003, 0.0, 0.0, 0.0, 0.045, 0.23, 0.479, 0.197, 0.043, 0.004, 0.001, 0.001, 0.0, 0.0]  Output:  [0.23, 0.45, 0.19, 0.08, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.273, 0.339, 0.268, 0.099, 0.015, 0.006, 0.0, 0.0, 0.0, 0.0, 0.63, 0.282, 0.076, 0.011, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0]  Output:  [0.93, 0.07, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Input:  [0.117, 0.111, 0.099, 0.096, 0.085, 0.082, 0.094, 0.106, 0.098, 0.112, 0.026, 0.108, 0.102, 0.095, 0.117, 0.105, 0.124, 0.111, 0.103, 0.109]  Output:  [0.11, 0.18, 0.2, 0.21, 0.09, 0.08, 0.05, 0.03, 0.02, 0.01]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-0.3</th>\n",
       "      <th>0.3-0.6</th>\n",
       "      <th>0.6-0.9</th>\n",
       "      <th>0.9-1.2</th>\n",
       "      <th>1.2-1.5</th>\n",
       "      <th>1.5-1.8</th>\n",
       "      <th>1.8-2.1</th>\n",
       "      <th>2.1-2.4</th>\n",
       "      <th>2.4-2.7</th>\n",
       "      <th>2.7-3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>0-0.5</th>\n",
       "      <th>0.5-1</th>\n",
       "      <th>1-1.5</th>\n",
       "      <th>1.5-2</th>\n",
       "      <th>2-2.5</th>\n",
       "      <th>2.5-3</th>\n",
       "      <th>3-3.5</th>\n",
       "      <th>3.5-4</th>\n",
       "      <th>4-4.5</th>\n",
       "      <th>4.5-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0-0.3  0.3-0.6  0.6-0.9  0.9-1.2  1.2-1.5  1.5-1.8  1.8-2.1  2.1-2.4  \\\n",
       "0  0.021    0.090    0.259    0.342    0.211    0.062    0.011    0.002   \n",
       "1  0.181    0.315    0.313    0.152    0.033    0.003    0.003    0.000   \n",
       "2  0.273    0.339    0.268    0.099    0.015    0.006    0.000    0.000   \n",
       "3  0.117    0.111    0.099    0.096    0.085    0.082    0.094    0.106   \n",
       "\n",
       "   2.4-2.7  2.7-3.0  ...  0-0.5  0.5-1  1-1.5  1.5-2  2-2.5  2.5-3  3-3.5  \\\n",
       "0    0.002    0.000  ...   0.47   0.51   0.02   0.00   0.00   0.00   0.00   \n",
       "1    0.000    0.000  ...   0.23   0.45   0.19   0.08   0.04   0.01   0.00   \n",
       "2    0.000    0.000  ...   0.93   0.07   0.00   0.00   0.00   0.00   0.00   \n",
       "3    0.098    0.112  ...   0.11   0.18   0.20   0.21   0.09   0.08   0.05   \n",
       "\n",
       "   3.5-4  4-4.5  4.5-5  \n",
       "0   0.00   0.00   0.00  \n",
       "1   0.00   0.00   0.00  \n",
       "2   0.00   0.00   0.00  \n",
       "3   0.03   0.02   0.01  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_excel('inference_set.xlsx')\n",
    "input_data.head()\n",
    "input_set = []\n",
    "for index, row in input_data.iterrows():\n",
    "    features = row.iloc[:20].tolist()\n",
    "    input_set.append(features)\n",
    "\n",
    "output_set = []\n",
    "for net_input in input_set:\n",
    "    net_output = bpnn.run(net_input)\n",
    "    output_set.append(net_output)\n",
    "    print(\"Input: \", net_input, \" Output: \", net_output)\n",
    "# Create a DataFrame for the output data\n",
    "\n",
    "header = list(data.columns)\n",
    "output_data = pd.DataFrame(columns=header)\n",
    "\n",
    "for i in range(len(input_set)):\n",
    "    row = input_set[i] + output_set[i]\n",
    "    output_data.loc[i] = row\n",
    "\n",
    "output_data.to_excel('result_set.xlsx', index=False)\n",
    "output_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
